{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57241aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2a4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f595dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the dataset from pickle file\n",
    "with open('C:/Users/joelt/Desktop/Jupyter/Nina_DB1/ninaprodb1test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "with open('C:/Users/joelt/Desktop/Jupyter/Nina_DB1/ninaprodb1train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09210ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, optimizers, Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba1daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e9f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 64\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "method = \"default\"\n",
    "dataset_type = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78d5b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Nina1Dataset object at 0x0000014543713940>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "class Nina1Dataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_data = self.dataframe[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_input_data = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for i, target_row in batch_data.iterrows():\n",
    "            data = target_row['emg'][:500]\n",
    "\n",
    "            # Zero-Padding\n",
    "            if len(data) < 500:\n",
    "                data = np.concatenate((data, np.zeros((500 - len(data), 10))), axis=0)\n",
    "\n",
    "            # Division data by time-segment\n",
    "            #input_data = np.transpose(data.reshape((25, 20, 10)), (0, 2, 1))\n",
    "            input_data = data.reshape((25, 20, 10))\n",
    "            label = target_row['stimulus']\n",
    "            #label = to_categorical(label)\n",
    "            batch_input_data.append(input_data)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        # Check if the batch size is smaller than the desired batch_size\n",
    "        if len(batch_data) < self.batch_size:\n",
    "            # Create a dummy batch with all elements set to zero\n",
    "            dummy_input_data = np.zeros((self.batch_size,) + input_data.shape, dtype=np.float32)\n",
    "            dummy_labels = np.zeros((self.batch_size,), dtype=np.int32)\n",
    "            dummy_input_data[:len(batch_input_data)] = np.array(batch_input_data)\n",
    "            dummy_labels[:len(batch_labels)] = np.array(batch_labels)\n",
    "            dummy_labels = to_categorical(dummy_labels,num_classes=52)  # Convert labels to one-hot encoding\n",
    "            \n",
    "            return dummy_input_data, dummy_labels\n",
    "        \n",
    "        batch_labels = to_categorical(batch_labels,num_classes=52)  # Convert labels to one-hot encoding\n",
    "        \n",
    "        return np.array(batch_input_data), np.array(batch_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "batch_size = 16\n",
    "train_dir = 'C:/Users/joelt/Desktop/Jupyter/Nina_DB1/ninaprodb1train.pkl'\n",
    "test_dir = 'C:/Users/joelt/Desktop/Jupyter/Nina_DB1/ninaprodb1test.pkl'\n",
    "\n",
    "# Set up dataset\n",
    "\n",
    "train = pd.read_pickle(train_dir)\n",
    "eval_data = pd.read_pickle(test_dir)\n",
    "\n",
    "# Load train data\n",
    "train_data = pd.read_pickle(train_dir)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.3, random_state=21)\n",
    "\n",
    "# Create train, test and validation datasets\n",
    "train_dataset = Nina1Dataset(train_data, batch_size=batch_size)\n",
    "val_dataset= Nina1Dataset(val_data, batch_size=batch_size)\n",
    "test_dataset= Nina1Dataset(eval_data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490b5813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emg</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>repetition</th>\n",
       "      <th>subject</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>[[0.0073, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>subject3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>[[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>subject4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>[[0.0049, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>subject4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>[[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>subject10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>[[0.0073, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>subject9</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>[[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>subject5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[[0.0098, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>subject1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>[[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>subject4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>[[0.0146, 0.0024, 0.0049, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>subject8</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>[[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>subject5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1646 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    emg stimulus repetition  \\\n",
       "712   [[0.0073, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...        5          9   \n",
       "890   [[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...        7          3   \n",
       "992   [[0.0049, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...        9          9   \n",
       "2304  [[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...       34          3   \n",
       "2131  [[0.0073, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...        4          6   \n",
       "...                                                 ...      ...        ...   \n",
       "1144  [[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...       36          6   \n",
       "48    [[0.0098, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...        6         10   \n",
       "772   [[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...        2          4   \n",
       "1848  [[0.0146, 0.0024, 0.0049, 0.0024, 0.0024, 0.00...        0          1   \n",
       "1231  [[0.0024, 0.0024, 0.0024, 0.0024, 0.0024, 0.00...        7         10   \n",
       "\n",
       "        subject rerepetition restimulus  \n",
       "712    subject3            0         -1  \n",
       "890    subject4            0         -1  \n",
       "992    subject4            9          9  \n",
       "2304  subject10            0         -1  \n",
       "2131   subject9            0         -1  \n",
       "...         ...          ...        ...  \n",
       "1144   subject5            0         -1  \n",
       "48     subject1            0         -1  \n",
       "772    subject4            4          2  \n",
       "1848   subject8            0         -1  \n",
       "1231   subject5           10          7  \n",
       "\n",
       "[1646 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e66744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 25, 20, 10)\n",
      "(None, 25, 10, 64)\n",
      "(None, 25, 2, 64)\n",
      "(None, 25, 1, 64)\n",
      "(None, 25, 64)\n",
      "(None, 25, 64)\n",
      "11\n",
      "(None, 25, 400)\n",
      "11\n",
      "(None, 25, 400)\n",
      "11\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - 15s 155ms/step - loss: 2.0929 - accuracy: 0.5347 - val_loss: 2.1102 - val_accuracy: 0.6020\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 1.3443 - accuracy: 0.6750 - val_loss: 1.2282 - val_accuracy: 0.6842\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 6s 138ms/step - loss: 1.0119 - accuracy: 0.7597 - val_loss: 1.0228 - val_accuracy: 0.8224\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.8642 - accuracy: 0.7806 - val_loss: 1.0102 - val_accuracy: 0.7697\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 6s 138ms/step - loss: 0.8312 - accuracy: 0.7764 - val_loss: 1.2218 - val_accuracy: 0.6579\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.8818 - accuracy: 0.7528 - val_loss: 0.9795 - val_accuracy: 0.7368\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.8589 - accuracy: 0.7764 - val_loss: 0.9014 - val_accuracy: 0.7993\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.7941 - accuracy: 0.7736 - val_loss: 1.0800 - val_accuracy: 0.7829\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 6s 139ms/step - loss: 0.8140 - accuracy: 0.7778 - val_loss: 1.0784 - val_accuracy: 0.6743\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.8084 - accuracy: 0.7792 - val_loss: 0.8270 - val_accuracy: 0.8191\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 6s 140ms/step - loss: 0.7472 - accuracy: 0.7847 - val_loss: 0.9923 - val_accuracy: 0.8257\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 6s 138ms/step - loss: 0.7583 - accuracy: 0.7847 - val_loss: 0.9104 - val_accuracy: 0.7961\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.7927 - accuracy: 0.7861 - val_loss: 0.8675 - val_accuracy: 0.8257\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 0.7115 - accuracy: 0.7889 - val_loss: 0.9569 - val_accuracy: 0.7467\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 7s 145ms/step - loss: 0.6789 - accuracy: 0.8097 - val_loss: 0.9396 - val_accuracy: 0.7401\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.6800 - accuracy: 0.8097 - val_loss: 1.0591 - val_accuracy: 0.7303\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 7s 150ms/step - loss: 0.6657 - accuracy: 0.8000 - val_loss: 1.0736 - val_accuracy: 0.7401\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 6s 138ms/step - loss: 0.6786 - accuracy: 0.7958 - val_loss: 0.9631 - val_accuracy: 0.7467\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.6284 - accuracy: 0.8014 - val_loss: 1.0101 - val_accuracy: 0.7730\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.6547 - accuracy: 0.8069 - val_loss: 1.0785 - val_accuracy: 0.7336\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Define the CNN-BiLSTM model\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, ReLU\n",
    "from tensorflow.keras.activations import tanh\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "def cnn(x):\n",
    "    #print(x.shape)\n",
    "    #x = Reshape((25, 20,10))(x)  \n",
    "    print(x.shape)\n",
    "    x = TimeDistributed((Conv1D(64, kernel_size=9, strides=2, padding='same', activation=tanh)))(x)\n",
    "    print(x.shape)\n",
    "    #(Batch, 10, 64)\n",
    "\n",
    "    x = TimeDistributed(MaxPooling1D(pool_size=8, strides=2))(x)\n",
    "    print(x.shape)\n",
    "    #(Batch, 2, 64)\n",
    "    \n",
    "    x = TimeDistributed((Conv1D(64, kernel_size=5, strides=2, padding='same', activation=tanh)))(x)\n",
    "    #(Batch, 1, 64)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-6, momentum=0.95))(x)\n",
    "    \n",
    "    x = TimeDistributed((Conv1D(64, kernel_size=5, strides=2, padding='same', activation=tanh)))(x)\n",
    "    print(x.shape)\n",
    "    #(Batch, 1, 64)\n",
    "    #x = TimeDistributed(Dropout(0.2093))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-6, momentum=0.95))(x)\n",
    "    \n",
    "    #x = TimeDistributed(ReLU())(Conv1D(64, kernel_size=3, strides=2, padding='same')(x))\n",
    "    x = TimeDistributed((Conv1D(64, kernel_size=3, strides=2, padding='same', activation=tanh)))(x)\n",
    "    #print(x.shape)\n",
    "    #(Batch, 1, 64)\n",
    "    #x = TimeDistributed(Dropout(0.2093))(x)\n",
    "    #x = TimeDistributed(BatchNormalization(epsilon=1e-6, momentum=0.95))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    print(x.shape)\n",
    "    # (Batch, 64)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Bi_LSTMModel(input_shape,x):\n",
    "    #model = Sequential()\n",
    "    # Hidden dimensions\n",
    "    hidden_dim = 200\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    x = Bidirectional(LSTM(hidden_dim, return_sequences=True, dropout=0.2093), input_shape=input_shape)(x)\n",
    "    #x = Dropout(0.2093)(x)\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    x = Bidirectional(LSTM(hidden_dim, return_sequences=True, dropout=0.2093))(x)\n",
    "\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    #x = Dropout(0.2093)(x)\n",
    "    x = Flatten()(x)\n",
    "    # ( ,10000)\n",
    "\n",
    "    return x\n",
    "def EMGHandNet(input_shape, num_classes):\n",
    "    # Define the input layer\n",
    "    x = Input(shape=input_shape)\n",
    "    inputs = x\n",
    "    #print(x.shape)\n",
    "    #(batch, 25, 20, 10)\n",
    "    #temp = [cnn(x[:, t, :, :]) for t in range(x.shape[1])]\n",
    "    #x = tf.stack(temp, axis=1)\n",
    "    #print(x.shape)\n",
    "    x = cnn(x)\n",
    "   \n",
    "    #print(x.shape)\n",
    "    x = Bi_LSTMModel(x.shape[1:],x)\n",
    "    #print(x.shape)\n",
    "    #x = Dropout(0.2093)(x)\n",
    "    x = Dense(512, activation='tanh')(x)\n",
    "    #print(x.shape)\n",
    "    x = Dropout(0.2093)(x)\n",
    "\n",
    "    # Add the output layer\n",
    "    output_layer = Dense(52, activation='softmax')(x)\n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "num_classes = 52  # Adjust based on the number of hand activity classes\n",
    "\n",
    "\n",
    "# Create an instance of the EMGHandNet model\n",
    "model = EMGHandNet((25,20,10), 52)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "#dtype = tf.float32\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.9\n",
    "batch_size = 16\n",
    "# Define your model and its optimizer\n",
    "# Define learning rate schedule\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "    # Compile the model with learning rate schedule\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_dataset,\n",
    "                    batch_size=16\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
